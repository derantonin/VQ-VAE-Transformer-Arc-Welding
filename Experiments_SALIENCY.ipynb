{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports/seeds\n",
    "import torch\n",
    "from torch import nn\n",
    "from model.mlp import MLP\n",
    "from dataloader.utils import get_val_test_ids\n",
    "from personal_utils import  (get_models_and_files, get_dataloaders_and_datasets,\n",
    "                             get_embedding_files, send_through_model, send_through_patch_model,\n",
    "                             send_through_decoder, generate_saliency_map, plot_saliency_map, alter_q_data, plot_reconstruction_difference)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.vq_vae import VectorQuantizedVAE\n",
    "from model.vq_vae_patch_embedd import VQVAEPatch\n",
    "\n",
    "_, _, _, train_data, val_data, test_data, train_labels, val_labels, test_labels = get_dataloaders_and_datasets()\n",
    "vqvae_v1_files = dict(model='VQ-VAE-asimow-best.ckpt', mlp='my_trained_mlp.ckpt', q_emb='q_emb_v1.npy', q_ind='q_ind_v1.npy', type='VQ-VAE')\n",
    "patch_vqvae_v1_files = dict(model='VQ-VAE-Patch-best-v1.ckpt', mlp='my_trained_mlp_on_patch_v1.ckpt', q_emb='patch_q_emb_v1.npy', q_ind='patch_q_ind_v1.npy', type='VQ-VAE-Patch')\n",
    "patch_vqvae_v2_files = dict(model='VQ-VAE-Patch-best-v2.ckpt', mlp='my_trained_mlp_on_patch_v2.ckpt', q_emb='patch_q_emb_v2.npy', q_ind='patch_q_ind_v2.npy', type='VQ-VAE-Patch')\n",
    "patch_vqvae_v4_files = dict(model='VQ-VAE-Patch-best-v4.ckpt', mlp='my_trained_mlp_on_patch_v4.ckpt', q_emb='patch_q_emb_v4.npy', q_ind='patch_q_ind_v4.npy', type='VQ-VAE-Patch')\n",
    "patch_vqvae_v5_files = dict(model='VQ-VAE-Patch-best-v5.ckpt', mlp='my_trained_mlp_on_patch_v5.ckpt', q_emb='patch_q_emb_v5.npy', q_ind='patch_q_ind_v5.npy', type='VQ-VAE-Patch')\n",
    "y_patch_vqvae_files = dict(model='Y-VQ-VAE-Patch-best.ckpt', mlp='my_trained_mlp_on_y_patch.ckpt', q_emb='y_patch_q_emb.npy', q_ind='y_patch_q_ind.npy', type='VQ-VAE-Patch')\n",
    "\n",
    "def get_files_and_models(files: dict):\n",
    "    # extract file paths from files dict\n",
    "    model_path = f\"./model_checkpoints/{files['type']}/{files['model']}\"\n",
    "    mlp_path = f\"./MLPs/{files['mlp']}\"\n",
    "    q_emb_path = f\"./created_files/{files['q_emb']}\"\n",
    "    q_ind_path = f\"./created_files/{files['q_ind']}\"\n",
    "\n",
    "    # load model\n",
    "    model_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    hparams = model_dict['hyper_parameters']\n",
    "    if files['type']=='VQ-VAE':\n",
    "        # hparams.pop('logger')\n",
    "        model = VectorQuantizedVAE(**hparams)\n",
    "        model.load_state_dict(model_dict['state_dict'])\n",
    "\n",
    "    elif files['type']=='VQ-VAE-Patch':\n",
    "        if 'use_improved_vq' not in hparams: hparams['use_improved_vq'] = None\n",
    "        model = VQVAEPatch(**hparams)\n",
    "        model.load_state_dict(model_dict['state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    # load mlp\n",
    "    my_mlp = MLP(input_size=model.enc_out_len, output_size=2, in_dim=model.embedding_dim, hidden_sizes=512)\n",
    "    my_mlp.load_state_dict(torch.load(mlp_path))\n",
    "    my_mlp.eval()\n",
    "\n",
    "    # extract codebook and load quantized embeddings\n",
    "    if files['type']=='VQ-VAE-Patch' and hparams[\"use_improved_vq\"]:\n",
    "        codebook = torch.round(model.vector_quantization.vq.codebooks[0], decimals=3)\n",
    "    else:\n",
    "        codebook = torch.round(model.vector_quantization.embedding.weight.data, decimals=3)\n",
    "    q_emb = torch.round(torch.tensor(np.load(q_emb_path), dtype=torch.float32), decimals=3)\n",
    "    q_ind = np.load(q_ind_path)\n",
    "    return dict(model=model, mlp=my_mlp, codebook=codebook, q_emb=q_emb, q_ind=q_ind, hparams=hparams, type=files['type'])\n",
    "\n",
    "# get dicts for every trained model combination containing model, mlp, codebook, q_emb, q_ind, hparams, type (VQ-VAE or VQ-VAE-Patch)\n",
    "vqvae_v1 = get_files_and_models(vqvae_v1_files)\n",
    "patch_vqvae_v1 = get_files_and_models(patch_vqvae_v1_files)\n",
    "patch_vqvae_v2 = get_files_and_models(patch_vqvae_v2_files)\n",
    "patch_vqvae_v4 = get_files_and_models(patch_vqvae_v4_files)\n",
    "patch_vqvae_v5 = get_files_and_models(patch_vqvae_v5_files)\n",
    "y_patch_vqvae = get_files_and_models(y_patch_vqvae_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "welding_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
